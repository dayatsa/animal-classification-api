{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.utils import class_weight, shuffle\n\nfrom tensorflow.keras import applications\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.layers import Dropout, Flatten, Dense\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-22T05:41:38.386532Z","iopub.execute_input":"2022-07-22T05:41:38.387031Z","iopub.status.idle":"2022-07-22T05:41:44.057289Z","shell.execute_reply.started":"2022-07-22T05:41:38.386988Z","shell.execute_reply":"2022-07-22T05:41:44.056316Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"foldernames = os.listdir('../input/animals10/raw-img')\ncategories = []\nfiles = []\ni = 0\nfor k, folder in enumerate(foldernames):\n    filenames = os.listdir(\"../input/animals10/raw-img/\" + folder);\n    for file in filenames:\n        files.append(\"../input/animals10/raw-img/\" + folder + \"/\" + file)\n        categories.append(k)\n        \ndf = pd.DataFrame({\n    'filename': files,\n    'category': categories\n})\ntrain_df = pd.DataFrame(columns=['filename', 'category'])\nfor i in range(10):\n    train_df = train_df.append(df[df.category == i].iloc[:500,:])\n\ntrain_df.head()\ntrain_df = train_df.reset_index(drop=True)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-07-22T05:41:44.059370Z","iopub.execute_input":"2022-07-22T05:41:44.059923Z","iopub.status.idle":"2022-07-22T05:41:45.875949Z","shell.execute_reply.started":"2022-07-22T05:41:44.059896Z","shell.execute_reply":"2022-07-22T05:41:45.875059Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"y = train_df['category']\nx = train_df['filename']\ny = train_df['category']\n\nx, y = shuffle(x, y, random_state=8)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T05:41:45.877946Z","iopub.execute_input":"2022-07-22T05:41:45.878751Z","iopub.status.idle":"2022-07-22T05:41:45.886598Z","shell.execute_reply.started":"2022-07-22T05:41:45.878710Z","shell.execute_reply":"2022-07-22T05:41:45.885802Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def centering_image(img):\n    size = [256,256]\n    \n    img_size = img.shape[:2]\n    \n    # centering\n    row = (size[1] - img_size[0]) // 2\n    col = (size[0] - img_size[1]) // 2\n    resized = np.zeros(list(size) + [img.shape[2]], dtype=np.uint8)\n    resized[row:(row + img.shape[0]), col:(col + img.shape[1])] = img\n\n    return resized\n\nimages = []\nwith tqdm(total=len(train_df)) as pbar:\n    for i, file_path in enumerate(train_df.filename.values):\n        #read image\n        img = cv2.imread(file_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        #resize\n        if(img.shape[0] > img.shape[1]):\n            tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n        else:\n            tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n\n        #centering\n        img = centering_image(cv2.resize(img, dsize=tile_size))\n\n        #out put 224*224px \n        img = img[16:240, 16:240]\n        images.append(img)\n        pbar.update(1)\n\nimages = np.array(images)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T05:41:45.889949Z","iopub.execute_input":"2022-07-22T05:41:45.890752Z","iopub.status.idle":"2022-07-22T05:42:21.577149Z","shell.execute_reply.started":"2022-07-22T05:41:45.890677Z","shell.execute_reply":"2022-07-22T05:42:21.576156Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"rows,cols = 2,5\nfig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(20,20))\nfor i in range(10):\n    path = train_df[train_df.category == i].values[2]\n#     image = cv2.imread(path[0])/\n    axes[i//cols, i%cols].set_title(path[0].split('/')[-2] + str(path[1]))\n    axes[i//cols, i%cols].imshow(images[train_df[train_df.filename == path[0]].index[0]])","metadata":{"execution":{"iopub.status.busy":"2022-07-22T05:42:21.578891Z","iopub.execute_input":"2022-07-22T05:42:21.579483Z","iopub.status.idle":"2022-07-22T05:42:22.820195Z","shell.execute_reply.started":"2022-07-22T05:42:21.579443Z","shell.execute_reply":"2022-07-22T05:42:22.819276Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data_num = len(y)\nrandom_index = np.random.permutation(data_num)\n\nx_shuffle = []\ny_shuffle = []\nfor i in range(data_num):\n    x_shuffle.append(images[random_index[i]])\n    y_shuffle.append(y[random_index[i]])\n    \nx = np.array(x_shuffle) \ny = np.array(y_shuffle)\nval_split_num = int(round(0.2*len(y)))\nx_train = x[val_split_num:]\ny_train = y[val_split_num:]\nx_test = x[:val_split_num]\ny_test = y[:val_split_num]\n\nprint('x_train', x_train.shape)\nprint('y_train', y_train.shape)\nprint('x_test', x_test.shape)\nprint('y_test', y_test.shape)\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n\nimg_rows, img_cols, img_channel = 224, 224, 3\nname_animal = []\nfor i in range(10):\n    path = train_df[train_df.category == i].values[2]\n    if path[0].split('/')[-2] == 'scoiattolo':\n        name_animal.append('squirrel')\n    elif path[0].split('/')[-2] == 'cavallo':\n        name_animal.append('horse')\n    elif path[0].split('/')[-2] == 'farfalla':\n        name_animal.append('butterfly')\n    elif path[0].split('/')[-2] == 'mucca':\n        name_animal.append('cow')\n    elif path[0].split('/')[-2] == 'gatto':\n        name_animal.append('cat')\n    elif path[0].split('/')[-2] == 'pecora':\n        name_animal.append('sheep')\n    elif path[0].split('/')[-2] == 'gallina':\n        name_animal.append('chicken')\n    elif path[0].split('/')[-2] == 'elefante':\n        name_animal.append('elephant')\n    elif path[0].split('/')[-2] == 'ragno':\n        name_animal.append('spider')\n    elif path[0].split('/')[-2] == 'cane':\n        name_animal.append('dog')","metadata":{"execution":{"iopub.status.busy":"2022-07-22T05:42:22.821249Z","iopub.execute_input":"2022-07-22T05:42:22.821565Z","iopub.status.idle":"2022-07-22T05:42:24.095114Z","shell.execute_reply.started":"2022-07-22T05:42:22.821535Z","shell.execute_reply":"2022-07-22T05:42:24.094153Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, img_channel))\n\nadd_model = Sequential()\nadd_model.add(Flatten(input_shape=base_model.output_shape[1:]))\nadd_model.add(Dense(256, activation='relu'))\nadd_model.add(Dense(10, activation='softmax'))\n\nmodel = Model(inputs=base_model.input, outputs=add_model(base_model.output))\nmodel.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-22T05:42:24.096790Z","iopub.execute_input":"2022-07-22T05:42:24.097182Z","iopub.status.idle":"2022-07-22T05:42:27.396554Z","shell.execute_reply.started":"2022-07-22T05:42:24.097145Z","shell.execute_reply":"2022-07-22T05:42:27.395550Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nepochs = 20\n\ntrain_datagen = ImageDataGenerator(\n        rotation_range=30, \n        width_shift_range=0.1,\n        height_shift_range=0.1, \n        horizontal_flip=True)\ntrain_datagen.fit(x_train)\n\n\nhistory = model.fit(\n    train_datagen.flow(x_train, y_train, batch_size=batch_size),\n    steps_per_epoch=x_train.shape[0] // batch_size,\n    epochs=epochs,\n    validation_data=(x_test, y_test),\n    callbacks=[ModelCheckpoint('VGG16-transferlearning.model', monitor='val_acc')]\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:00:03.349863Z","iopub.execute_input":"2022-07-22T06:00:03.350226Z","iopub.status.idle":"2022-07-22T06:19:39.637344Z","shell.execute_reply.started":"2022-07-22T06:00:03.350196Z","shell.execute_reply":"2022-07-22T06:19:39.636304Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(\"CNN: Epochs={0:d}, Train accuracy={1:.5f}, Validation accuracy={2:.5f}\".format(epochs,history.history['accuracy'][epochs-1],history.history['val_accuracy'][epochs-1]))\ndef show_plots(history):\n    \"\"\" Useful function to view plot of loss values & accuracies across the various epochs \"\"\"\n    loss_vals = history['loss']\n    val_loss_vals = history['val_loss']\n    epochs = range(1, len(history['accuracy'])+1)\n    \n    f, ax = plt.subplots(nrows=1,ncols=2,figsize=(16,4))\n    \n    # plot losses on ax[0]\n    ax[0].plot(epochs, loss_vals, color='navy',marker='o', linestyle=' ', label='Training Loss')\n    ax[0].plot(epochs, val_loss_vals, color='firebrick', marker='*', label='Validation Loss')\n    ax[0].set_title('Training & Validation Loss')\n    ax[0].set_xlabel('Epochs')\n    ax[0].set_ylabel('Loss')\n    ax[0].legend(loc='best')\n    ax[0].grid(True)\n    \n    # plot accuracies\n    acc_vals = history['accuracy']\n    val_acc_vals = history['val_accuracy']\n\n    ax[1].plot(epochs, acc_vals, color='navy', marker='o', ls=' ', label='Training Accuracy')\n    ax[1].plot(epochs, val_acc_vals, color='firebrick', marker='*', label='Validation Accuracy')\n    ax[1].set_title('Training & Validation Accuracy')\n    ax[1].set_xlabel('Epochs')\n    ax[1].set_ylabel('Accuracy')\n    ax[1].legend(loc='best')\n    ax[1].grid(True)\n    \n    plt.show()\n    plt.close()\n    \n    # delete locals from heap before exiting\n    del loss_vals, val_loss_vals, epochs, acc_vals, val_acc_vals\nshow_plots(history.history)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:19:39.640337Z","iopub.execute_input":"2022-07-22T06:19:39.641093Z","iopub.status.idle":"2022-07-22T06:19:39.992111Z","shell.execute_reply.started":"2022-07-22T06:19:39.641029Z","shell.execute_reply":"2022-07-22T06:19:39.991027Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"test_images = []\nj = 39 # change this to get different images\nfor i in range(10):\n    path = train_df[train_df.category == i].values[j]\n    a = images[train_df[train_df.filename == path[0]].index[0]]\n    img = np.array(a)\n    img = img[:, :, ::-1].copy() \n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    if(img.shape[0] > img.shape[1]):\n        tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n    else:\n        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n    img = centering_image(cv2.resize(img, dsize=tile_size))\n    img = img[16:240, 16:240]\n    test_images.append(img)\n\ntest_images = np.array(test_images).reshape(-1,224,224,3)\nsomething = model.predict(test_images)\nanimals = name_animal\ni = 0\nfor pred in something:\n    path = train_df[train_df.category == i].values[2]\n    plt.imshow(test_images[i])\n    plt.show()\n    print('Actual  :', animals[i])\n    print('Predict :', animals[np.where(pred.max() == pred)[0][0]])\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:19:51.932325Z","iopub.execute_input":"2022-07-22T06:19:51.932675Z","iopub.status.idle":"2022-07-22T06:19:55.201208Z","shell.execute_reply.started":"2022-07-22T06:19:51.932644Z","shell.execute_reply":"2022-07-22T06:19:55.200266Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflowjs","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:20:42.788938Z","iopub.execute_input":"2022-07-22T06:20:42.789731Z","iopub.status.idle":"2022-07-22T06:21:14.923512Z","shell.execute_reply.started":"2022-07-22T06:20:42.789689Z","shell.execute_reply":"2022-07-22T06:21:14.922278Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import tensorflowjs as tfjs\n\ntfjs.converters.save_keras_model(model, \"./jsmodel.json\")","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:21:44.568776Z","iopub.execute_input":"2022-07-22T06:21:44.569152Z","iopub.status.idle":"2022-07-22T06:21:45.173590Z","shell.execute_reply.started":"2022-07-22T06:21:44.569117Z","shell.execute_reply":"2022-07-22T06:21:45.172614Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:25:43.196183Z","iopub.execute_input":"2022-07-22T06:25:43.196545Z","iopub.status.idle":"2022-07-22T06:25:43.201698Z","shell.execute_reply.started":"2022-07-22T06:25:43.196516Z","shell.execute_reply":"2022-07-22T06:25:43.200461Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'jsmodel.json')","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:25:56.749003Z","iopub.execute_input":"2022-07-22T06:25:56.749505Z","iopub.status.idle":"2022-07-22T06:25:56.774511Z","shell.execute_reply.started":"2022-07-22T06:25:56.749459Z","shell.execute_reply":"2022-07-22T06:25:56.773178Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}